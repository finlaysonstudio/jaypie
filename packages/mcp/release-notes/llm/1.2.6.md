---
version: 1.2.6
date: 2025-01-21
summary: Add configurable fallback provider chain for automatic retry with alternative providers
---

## Changes

### New Features

- **Fallback Provider Support**: Configure a chain of fallback providers that automatically retry failed `operate()` calls when the primary provider fails with an unrecoverable error.

### Usage

```typescript
// Instance-level configuration
const llm = new Llm("anthropic", {
  model: "claude-sonnet-4",
  fallback: [
    { provider: "openai", model: "gpt-4o" },
    { provider: "gemini", model: "gemini-2.0-flash" },
  ],
});

// Per-call override
const response = await llm.operate(input, {
  fallback: [{ provider: "openai", model: "gpt-4o" }],
});

// Disable fallback for specific call
const response = await llm.operate(input, { fallback: false });

// Static method with fallback
const response = await Llm.operate(input, {
  model: "claude-sonnet-4",
  fallback: [{ provider: "openai", model: "gpt-4o" }],
});
```

### Response Metadata

The `LlmOperateResponse` now includes:
- `provider`: Which provider actually handled the request
- `fallbackUsed`: `true` if a fallback provider was used
- `fallbackAttempts`: Number of providers tried (1 = primary only)

### New Type

```typescript
interface LlmFallbackConfig {
  provider: string;
  model?: string;
  apiKey?: string;
}
```
